{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 헬로 딥러닝 MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 MNIST 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 텐서플로 임포트, 텐서플로에 내장된 mnist.input\\_data 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-bed9dddec7b6>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. MNIST 손글씨 이미지는 28 $\\times$ 28 픽셀이다. 즉 784개의 특징으로 이루어져 있다. 레이블은 0에서 9까지인 10개의 분류로 나누어 진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터를 적당한 크기로 잘라서 학습시키는데, 이것을 **미니배치**라 한다.\n",
    "- None은 한 번에 학습시킬 이미지의 개수, 즉 배치 크기를 정하는 자리이다. 한번에 학습할 개수를 계속 바꿔가면서 실험해보려면 None으로 넣어주면 텐서플로가 알아서 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모습\n",
    "\n",
    "```\n",
    "784(입력, 특징 개수) - > 256(첫 번째 은닉층 뉴런 개수) -> 256(두 번째 은닉층 뉴런 개수) -> 10(결과값 0-9 분류 개수)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 코드로 구성하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 다음으로 tf.nn.softmax_cross_entropy_with_logtis 함수를 이용하여 각 이미지에 대한 손실값(실제값과 예측값의 차이)을 구하고 tf.reduce_mean 함수를 이용해 미니배치의 평균 손실값을 구한다. 그리고 tf.train.AdamOptimizer 함수를 사용하여 이 손실값을 최소화하는 최적화를 수행하도록 그래프를 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델 초기화, 학습 진행할 세션 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터 전체를 학습하는 일을 총 15번 반복하자. 학습 데이터 전체를 한 바퀴 도는 것을 **에포크**(epoch)라 한다.\n",
    "\n",
    "아래 반복문 학습한 데이터를 배치 크기만큼 가져온 뒤, 입력값 데이터는 batch\\_xs, 출력값 데이터는 batch\\_ys에 저장한다. 다음으로 sess.run을 이용하려 최적화시키고 손실값을 가져와서 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 AVG. cost= 0.411\n",
      "Epoch: 0002 AVG. cost= 0.149\n",
      "Epoch: 0003 AVG. cost= 0.096\n",
      "Epoch: 0004 AVG. cost= 0.069\n",
      "Epoch: 0005 AVG. cost= 0.052\n",
      "Epoch: 0006 AVG. cost= 0.041\n",
      "Epoch: 0007 AVG. cost= 0.030\n",
      "Epoch: 0008 AVG. cost= 0.025\n",
      "Epoch: 0009 AVG. cost= 0.021\n",
      "Epoch: 0010 AVG. cost= 0.017\n",
      "Epoch: 0011 AVG. cost= 0.016\n",
      "Epoch: 0012 AVG. cost= 0.014\n",
      "Epoch: 0013 AVG. cost= 0.014\n",
      "Epoch: 0014 AVG. cost= 0.009\n",
      "Epoch: 0015 AVG. cost= 0.012\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size=batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                              feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        \n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print ('Epoch:', '%04d' % (epoch + 1),\n",
    "           'AVG. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print ('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 결과를 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. tf.cast를 이용해 is\\_correct를 0과 1로 변환한다. 그리고 변환한 값들을 tf.reduce\\_mean을 이용해 평균을 내면 그것이 바로 정확도가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9788\n"
     ]
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "print ('정확도:', sess.run(accuracy,\n",
    "                         feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 AVG. cost= 0.216\n",
      "Epoch: 0002 AVG. cost= 0.092\n",
      "Epoch: 0003 AVG. cost= 0.064\n",
      "Epoch: 0004 AVG. cost= 0.049\n",
      "Epoch: 0005 AVG. cost= 0.040\n",
      "Epoch: 0006 AVG. cost= 0.031\n",
      "Epoch: 0007 AVG. cost= 0.032\n",
      "Epoch: 0008 AVG. cost= 0.028\n",
      "Epoch: 0009 AVG. cost= 0.022\n",
      "Epoch: 0010 AVG. cost= 0.022\n",
      "Epoch: 0011 AVG. cost= 0.021\n",
      "Epoch: 0012 AVG. cost= 0.021\n",
      "Epoch: 0013 AVG. cost= 0.012\n",
      "Epoch: 0014 AVG. cost= 0.017\n",
      "Epoch: 0015 AVG. cost= 0.016\n",
      "Epoch: 0016 AVG. cost= 0.012\n",
      "Epoch: 0017 AVG. cost= 0.018\n",
      "Epoch: 0018 AVG. cost= 0.010\n",
      "Epoch: 0019 AVG. cost= 0.018\n",
      "Epoch: 0020 AVG. cost= 0.011\n",
      "Epoch: 0021 AVG. cost= 0.008\n",
      "Epoch: 0022 AVG. cost= 0.016\n",
      "Epoch: 0023 AVG. cost= 0.010\n",
      "Epoch: 0024 AVG. cost= 0.011\n",
      "Epoch: 0025 AVG. cost= 0.008\n",
      "Epoch: 0026 AVG. cost= 0.013\n",
      "Epoch: 0027 AVG. cost= 0.011\n",
      "Epoch: 0028 AVG. cost= 0.008\n",
      "Epoch: 0029 AVG. cost= 0.007\n",
      "Epoch: 0030 AVG. cost= 0.008\n",
      "최적화 완료!\n",
      "정확도: 0.9771\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "################\n",
    "# 신경망 모델 구성 #\n",
    "################\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros([256]))\n",
    "L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros([256]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "B3 = tf.Variable(tf.zeros([10]))\n",
    "model = tf.add(tf.matmul(L2, W3), B3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "################\n",
    "# 신경망 모델 학습 #\n",
    "################\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print ('Epoch:', '%04d' % (epoch + 1),\n",
    "           'AVG. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print ('최적화 완료!')\n",
    "\n",
    "###########\n",
    "# 결과 확인 #\n",
    "##########\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, axis=1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print ('정확도:', sess.run(accuracy,\n",
    "                         feed_dict = {X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 드롭아웃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **드롭아웃**은 과적합 문제를 가장 잘 해결할 수 있는 방법 중 하나이다. 학습시 전체 신경망 중 일부만을 사용하도록 하는 것이다. \n",
    "- 즉, 학습 단계마다 일부 뉴런을 제거(사용하지 않도록) 함으로써, 일부 특징이 특정 뉴런들에 고정되는 것을 막아 가중치의 균형을 잡도록 하여 과적합을 방지한다. \n",
    "- 다만, 학습 시 일부 뉴런을 학습시키지 않기 때문에 신경망이 충분히 학습되기까지의 시간은 조금 더 오래 걸린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 드롭아웃은 텐서플로가 기본으로 지원해주기 때문에 아주 간단하게 적용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros([256]))\n",
    "L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, 0.8)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros([256]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L1, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계층 구성의 마지막에 tf.nn.dropout 함수를 사용하기만 하면 된다. 0.8은 사용할 뉼너의 비율을 뜻한다.\n",
    "- 학습이 끝난 후, 예측을 할 시에는 신경망 전체를 사용하도록 해야 한다. keep\\_prob 플레이스홀더를 만들어서, 학습 시에는 0.8을 넣어 드롭아웃을 사용하도록 하고, 예측 시에는 1을 넣어 신경망 전체를 사용하도록 만들어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.977\n"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros([256]))\n",
    "L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros([256]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "# 학습 코드: keep_prob를 0.8로 넣어준다.\n",
    "_, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y:batch_ys, keep_prob:0.8})\n",
    "\n",
    "# 예측 코드: keep_prob를 1로 넣어준다.\n",
    "print ('정확도:', sess.run(accuracy,\n",
    "                         feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels,\n",
    "                                    keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 AVG. cost= 0.312\n",
      "Epoch: 0002 AVG. cost= 0.178\n",
      "Epoch: 0003 AVG. cost= 0.146\n",
      "Epoch: 0004 AVG. cost= 0.128\n",
      "Epoch: 0005 AVG. cost= 0.113\n",
      "Epoch: 0006 AVG. cost= 0.103\n",
      "Epoch: 0007 AVG. cost= 0.093\n",
      "Epoch: 0008 AVG. cost= 0.088\n",
      "Epoch: 0009 AVG. cost= 0.081\n",
      "Epoch: 0010 AVG. cost= 0.077\n",
      "Epoch: 0011 AVG. cost= 0.073\n",
      "Epoch: 0012 AVG. cost= 0.067\n",
      "Epoch: 0013 AVG. cost= 0.068\n",
      "Epoch: 0014 AVG. cost= 0.064\n",
      "Epoch: 0015 AVG. cost= 0.057\n",
      "Epoch: 0016 AVG. cost= 0.058\n",
      "Epoch: 0017 AVG. cost= 0.057\n",
      "Epoch: 0018 AVG. cost= 0.052\n",
      "Epoch: 0019 AVG. cost= 0.053\n",
      "Epoch: 0020 AVG. cost= 0.048\n",
      "Epoch: 0021 AVG. cost= 0.049\n",
      "Epoch: 0022 AVG. cost= 0.047\n",
      "Epoch: 0023 AVG. cost= 0.042\n",
      "Epoch: 0024 AVG. cost= 0.042\n",
      "Epoch: 0025 AVG. cost= 0.046\n",
      "Epoch: 0026 AVG. cost= 0.041\n",
      "Epoch: 0027 AVG. cost= 0.040\n",
      "Epoch: 0028 AVG. cost= 0.038\n",
      "Epoch: 0029 AVG. cost= 0.039\n",
      "Epoch: 0030 AVG. cost= 0.037\n",
      "Epoch: 0031 AVG. cost= 0.033\n",
      "Epoch: 0032 AVG. cost= 0.035\n",
      "Epoch: 0033 AVG. cost= 0.037\n",
      "Epoch: 0034 AVG. cost= 0.035\n",
      "Epoch: 0035 AVG. cost= 0.034\n",
      "Epoch: 0036 AVG. cost= 0.037\n",
      "Epoch: 0037 AVG. cost= 0.032\n",
      "Epoch: 0038 AVG. cost= 0.031\n",
      "Epoch: 0039 AVG. cost= 0.031\n",
      "Epoch: 0040 AVG. cost= 0.032\n",
      "Epoch: 0041 AVG. cost= 0.029\n",
      "Epoch: 0042 AVG. cost= 0.030\n",
      "Epoch: 0043 AVG. cost= 0.028\n",
      "Epoch: 0044 AVG. cost= 0.027\n",
      "Epoch: 0045 AVG. cost= 0.028\n",
      "Epoch: 0046 AVG. cost= 0.029\n",
      "Epoch: 0047 AVG. cost= 0.025\n",
      "Epoch: 0048 AVG. cost= 0.029\n",
      "Epoch: 0049 AVG. cost= 0.026\n",
      "Epoch: 0050 AVG. cost= 0.026\n",
      "Epoch: 0051 AVG. cost= 0.025\n",
      "Epoch: 0052 AVG. cost= 0.027\n",
      "Epoch: 0053 AVG. cost= 0.025\n",
      "Epoch: 0054 AVG. cost= 0.028\n",
      "Epoch: 0055 AVG. cost= 0.025\n",
      "Epoch: 0056 AVG. cost= 0.024\n",
      "Epoch: 0057 AVG. cost= 0.023\n",
      "Epoch: 0058 AVG. cost= 0.021\n",
      "Epoch: 0059 AVG. cost= 0.023\n",
      "Epoch: 0060 AVG. cost= 0.023\n",
      "Epoch: 0061 AVG. cost= 0.021\n",
      "Epoch: 0062 AVG. cost= 0.022\n",
      "Epoch: 0063 AVG. cost= 0.025\n",
      "Epoch: 0064 AVG. cost= 0.022\n",
      "Epoch: 0065 AVG. cost= 0.021\n",
      "Epoch: 0066 AVG. cost= 0.024\n",
      "Epoch: 0067 AVG. cost= 0.021\n",
      "Epoch: 0068 AVG. cost= 0.022\n",
      "Epoch: 0069 AVG. cost= 0.023\n",
      "Epoch: 0070 AVG. cost= 0.021\n",
      "Epoch: 0071 AVG. cost= 0.022\n",
      "Epoch: 0072 AVG. cost= 0.020\n",
      "Epoch: 0073 AVG. cost= 0.022\n",
      "Epoch: 0074 AVG. cost= 0.018\n",
      "Epoch: 0075 AVG. cost= 0.020\n",
      "Epoch: 0076 AVG. cost= 0.020\n",
      "Epoch: 0077 AVG. cost= 0.019\n",
      "Epoch: 0078 AVG. cost= 0.019\n",
      "Epoch: 0079 AVG. cost= 0.021\n",
      "Epoch: 0080 AVG. cost= 0.019\n",
      "Epoch: 0081 AVG. cost= 0.019\n",
      "Epoch: 0082 AVG. cost= 0.019\n",
      "Epoch: 0083 AVG. cost= 0.018\n",
      "Epoch: 0084 AVG. cost= 0.019\n",
      "Epoch: 0085 AVG. cost= 0.020\n",
      "Epoch: 0086 AVG. cost= 0.019\n",
      "Epoch: 0087 AVG. cost= 0.020\n",
      "Epoch: 0088 AVG. cost= 0.016\n",
      "Epoch: 0089 AVG. cost= 0.017\n",
      "Epoch: 0090 AVG. cost= 0.019\n",
      "Epoch: 0091 AVG. cost= 0.019\n",
      "Epoch: 0092 AVG. cost= 0.018\n",
      "Epoch: 0093 AVG. cost= 0.018\n",
      "Epoch: 0094 AVG. cost= 0.018\n",
      "Epoch: 0095 AVG. cost= 0.017\n",
      "Epoch: 0096 AVG. cost= 0.017\n",
      "Epoch: 0097 AVG. cost= 0.017\n",
      "Epoch: 0098 AVG. cost= 0.017\n",
      "Epoch: 0099 AVG. cost= 0.018\n",
      "Epoch: 0100 AVG. cost= 0.019\n",
      "최적화 완료!\n",
      "정확도: 0.9805\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "################\n",
    "# 신경망 모델 구성 #\n",
    "################\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros([256]))\n",
    "L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros([256]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "B3 = tf.Variable(tf.zeros([10]))\n",
    "model = tf.add(tf.matmul(L2, W3), B3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "################\n",
    "# 신경망 모델 학습 #\n",
    "################\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict = {X: batch_xs,\n",
    "                                            Y: batch_ys,\n",
    "                                            keep_prob: 0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print ('Epoch:', '%04d' % (epoch + 1),\n",
    "           'AVG. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print ('최적화 완료!')\n",
    "\n",
    "###########\n",
    "# 결과 확인 #\n",
    "##########\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, axis=1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print ('정확도:', sess.run(accuracy,\n",
    "                         feed_dict = {X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels,\n",
    "                                      keep_prob: 1})) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. matplotlib의 pyplot 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 테스트 데이터를 이용해 예측 모델을 실행하고 결과값을 labels에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sess.run(model,\n",
    "                  feed_dict={X: mnist.test.images,\n",
    "                             Y: mnist.test.labels,\n",
    "                             keep_prob: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 그런 다음에 손글씨를 출력할 그래프를 준비한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    # 2행 5열의 그래프를 만들고, i + 1 번째에 숫자 이미지를 출력한다.\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    # 이미지를 깨끗하게 출력하기 위해 x와 y의 눈금을 출력하지 않는다.\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    # 출력한 이미지 위에 예측한 숫자를 출력한다.\n",
    "    # np.argmax는 tf.argmax와 같은 기능의 함수이다.\n",
    "    # 결괏값인 labels의 i번째 요소가 원-핫 인코딩 형식으로 되어 있으므로, 해당 배열에서 가장 높은 값을 가진 인덱스를 예측한 숫자로 출력한다.\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    # 1차원 배열로 되어 있는 i번째 이미지를 28 x 28 형식의 배열로 변형하여 이미지 형태로 출력한다.\n",
    "    # cmap 파라미터를 통해 이미지를 그레이스케일로 출력한다.\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)), cmap=plt.cm.gray_r)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 AVG. cost= 0.565\n",
      "Epoch: 0002 AVG. cost= 0.319\n",
      "Epoch: 0003 AVG. cost= 0.267\n",
      "Epoch: 0004 AVG. cost= 0.242\n",
      "Epoch: 0005 AVG. cost= 0.221\n",
      "Epoch: 0006 AVG. cost= 0.208\n",
      "Epoch: 0007 AVG. cost= 0.204\n",
      "Epoch: 0008 AVG. cost= 0.194\n",
      "Epoch: 0009 AVG. cost= 0.190\n",
      "Epoch: 0010 AVG. cost= 0.184\n",
      "Epoch: 0011 AVG. cost= 0.177\n",
      "Epoch: 0012 AVG. cost= 0.177\n",
      "Epoch: 0013 AVG. cost= 0.175\n",
      "Epoch: 0014 AVG. cost= 0.169\n",
      "Epoch: 0015 AVG. cost= 0.167\n",
      "Epoch: 0016 AVG. cost= 0.165\n",
      "Epoch: 0017 AVG. cost= 0.167\n",
      "Epoch: 0018 AVG. cost= 0.161\n",
      "Epoch: 0019 AVG. cost= 0.157\n",
      "Epoch: 0020 AVG. cost= 0.157\n",
      "Epoch: 0021 AVG. cost= 0.149\n",
      "Epoch: 0022 AVG. cost= 0.147\n",
      "Epoch: 0023 AVG. cost= 0.157\n",
      "Epoch: 0024 AVG. cost= 0.137\n",
      "Epoch: 0025 AVG. cost= 0.145\n",
      "Epoch: 0026 AVG. cost= 0.141\n",
      "Epoch: 0027 AVG. cost= 0.147\n",
      "Epoch: 0028 AVG. cost= 0.146\n",
      "Epoch: 0029 AVG. cost= 0.138\n",
      "Epoch: 0030 AVG. cost= 0.137\n",
      "최적화 완료!\n",
      "정확도: 0.9689\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot=True)\n",
    "\n",
    "################\n",
    "# 신경망 모델 구성 #\n",
    "################\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros([256]))\n",
    "L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros([256]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "B3 = tf.Variable(tf.zeros([10]))\n",
    "model = tf.add(tf.matmul(L2, W3), B3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "################\n",
    "# 신경망 모델 학습 #\n",
    "################\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict = {X: batch_xs,\n",
    "                                            Y: batch_ys,\n",
    "                                            keep_prob: 0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print ('Epoch:', '%04d' % (epoch + 1),\n",
    "           'AVG. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "    \n",
    "print ('최적화 완료!')\n",
    "\n",
    "###########\n",
    "# 결과 확인 #\n",
    "########## \n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, axis=1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print ('정확도:', sess.run(accuracy,\n",
    "                         feed_dict = {X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels,\n",
    "                                      keep_prob: 1}))\n",
    "\n",
    "########################\n",
    "# 결과 확인 (matplotlib) #\n",
    "#######################\n",
    "\n",
    "labels = sess.run(model, feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels,\n",
    "                                    keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    # 2행 5열의 그래프를 만들고, i + 1 번째에 숫자 이미지를 출력한다.\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    # 이미지를 깨끗하게 출력하기 위해 x와 y의 눈금을 출력하지 않는다.\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    # 출력한 이미지 위에 예측한 숫자를 출력한다.\n",
    "    # np.argmax는 tf.argmax와 같은 기능의 함수이다.\n",
    "    # 결괏값인 labels의 i번째 요소가 원-핫 인코딩 형식으로 되어 있으므로, 해당 배열에서 가장 높은 값을 가진 인덱스를 예측한 숫자로 출력한다.\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    # 1차원 배열로 되어 있는 i번째 이미지를 28 x 28 형식의 배열로 변형하여 이미지 형태로 출력한다.\n",
    "    # cmap 파라미터를 통해 이미지를 그레이스케일로 출력한다.\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)), cmap=plt.cm.gray_r)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지와 레이블을 범위를 변경해가면서 출력해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(range(11, 21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    # 2행 5열의 그래프를 만들고, i + 1 번째에 숫자 이미지를 출력한다.\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    # 이미지를 깨끗하게 출력하기 위해 x와 y의 눈금을 출력하지 않는다.\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    # 출력한 이미지 위에 예측한 숫자를 출력한다.\n",
    "    # np.argmax는 tf.argmax와 같은 기능의 함수이다.\n",
    "    # 결괏값인 labels의 i번째 요소가 원-핫 인코딩 형식으로 되어 있으므로, 해당 배열에서 가장 높은 값을 가진 인덱스를 예측한 숫자로 출력한다.\n",
    "    subplot.set_title('%d' % np.argmax(labels[i+10]))\n",
    "    # 1차원 배열로 되어 있는 i번째 이미지를 28 x 28 형식의 배열로 변형하여 이미지 형태로 출력한다.\n",
    "    # cmap 파라미터를 통해 이미지를 그레이스케일로 출력한다.\n",
    "    subplot.imshow(mnist.test.images[i+10].reshape((28, 28)), cmap=plt.cm.gray_r)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습시킨 모델을 저장하고 예측 결과만 빠르게 출력해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c4793fd12062>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Restoring parameters from ./model_ch6/dnn_mnist.ckpt-0\n",
      "Epoch: 0001 AVG. cost= 0.184\n",
      "Epoch: 0002 AVG. cost= 0.173\n",
      "Epoch: 0003 AVG. cost= 0.170\n",
      "Epoch: 0004 AVG. cost= 0.174\n",
      "Epoch: 0005 AVG. cost= 0.169\n",
      "Epoch: 0006 AVG. cost= 0.166\n",
      "Epoch: 0007 AVG. cost= 0.165\n",
      "Epoch: 0008 AVG. cost= 0.159\n",
      "Epoch: 0009 AVG. cost= 0.159\n",
      "Epoch: 0010 AVG. cost= 0.156\n",
      "최적화 완료!\n",
      "정확도: 0.968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot=True)\n",
    "\n",
    "################\n",
    "# 신경망 모델 구성 #\n",
    "################\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros([256]))\n",
    "L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros([256]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "B3 = tf.Variable(tf.zeros([10]))\n",
    "model = tf.add(tf.matmul(L2, W3), B3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "################\n",
    "# 신경망 모델 학습 #\n",
    "################\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model_ch6/')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print (\"it's new, not resotred\")\n",
    "    \n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict = {X: batch_xs,\n",
    "                                            Y: batch_ys,\n",
    "                                            keep_prob: 0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print ('Epoch:', '%04d' % (epoch + 1),\n",
    "           'AVG. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "saver.save(sess, './model_ch6/dnn_mnist.ckpt', global_step=global_step)    \n",
    "\n",
    "print ('최적화 완료!')\n",
    "\n",
    "###########\n",
    "# 결과 확인 #\n",
    "########## \n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, axis=1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print ('정확도:', sess.run(accuracy,\n",
    "                         feed_dict = {X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels,\n",
    "                                      keep_prob: 1}))\n",
    "\n",
    "########################\n",
    "# 결과 확인 (matplotlib) #\n",
    "#######################\n",
    "\n",
    "labels = sess.run(model, feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels,\n",
    "                                    keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    # 2행 5열의 그래프를 만들고, i + 1 번째에 숫자 이미지를 출력한다.\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    # 이미지를 깨끗하게 출력하기 위해 x와 y의 눈금을 출력하지 않는다.\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    # 출력한 이미지 위에 예측한 숫자를 출력한다.\n",
    "    # np.argmax는 tf.argmax와 같은 기능의 함수이다.\n",
    "    # 결괏값인 labels의 i번째 요소가 원-핫 인코딩 형식으로 되어 있으므로, 해당 배열에서 가장 높은 값을 가진 인덱스를 예측한 숫자로 출력한다.\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    # 1차원 배열로 되어 있는 i번째 이미지를 28 x 28 형식의 배열로 변형하여 이미지 형태로 출력한다.\n",
    "    # cmap 파라미터를 통해 이미지를 그레이스케일로 출력한다.\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)), cmap=plt.cm.gray_r)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-a49bd0af59a5>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Restoring parameters from ./model_ch6/dnn_mnist.ckpt-0\n",
      "정확도: 0.9658\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot=True)\n",
    "\n",
    "################\n",
    "# 신경망 모델 구성 #\n",
    "################\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.zeros([256]))\n",
    "L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "B2 = tf.Variable(tf.zeros([256]))\n",
    "L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "B3 = tf.Variable(tf.zeros([10]))\n",
    "model = tf.add(tf.matmul(L2, W3), B3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# 로딩 이전에 세션 열고\n",
    "sess = tf.Session()\n",
    "\n",
    "# tf.global_variables을 통해 앞서 정의한 변수들을 가져오는 함수이다. 이전에 학습한 결과를 불러와서 여기에 담는다.\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# 해당 체크포인트에서\n",
    "ckpt = tf.train.get_checkpoint_state('./model_ch6/')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    # 불러와서 담는다\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    \n",
    "# 예측\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print ('정확도:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서플로로 손실값 그래프를 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "it's new, not resotred\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-4eb3ca6ff33c>\", line 14, in <module>\n    X = tf.placeholder(tf.float32, [None, 784])\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4848, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-690216bef278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtotal_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder', defined at:\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-4eb3ca6ff33c>\", line 14, in <module>\n    X = tf.placeholder(tf.float32, [None, 784])\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1808, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4848, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/smfc/.pyenv/versions/3.6.4/envs/golbin-3min-tensor/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,784]\n\t [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[?,784], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data\", one_hot=True)\n",
    "\n",
    "################\n",
    "# 신경망 모델 구성 #\n",
    "################\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.name_scope('layer1'):\n",
    "    W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "    B1 = tf.Variable(tf.zeros([256]))\n",
    "    L1 = tf.add(tf.matmul(X, W1), B1)\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "with tf.name_scope('layer2'):\n",
    "    W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "    B2 = tf.Variable(tf.zeros([256]))\n",
    "    L2 = tf.add(tf.matmul(L1, W2), B2)\n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "    B3 = tf.Variable(tf.zeros([10]))\n",
    "    model = tf.add(tf.matmul(L2, W3), B3)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "    \n",
    "    tf.summary.scalar('cost', cost)\n",
    "\n",
    "################\n",
    "# 신경망 모델 학습 #\n",
    "################\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print (\"it's new, not resotred\")\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./logs2', sess.graph)\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict = {X: batch_xs,\n",
    "                                            Y: batch_ys,\n",
    "                                            keep_prob: 0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    summary = sess.run(merged, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "    writer.add_summary(summary, global_step=sess.run(global_step))\n",
    "        \n",
    "    print ('Epoch:', '%04d' % (epoch + 1),\n",
    "           'AVG. cost=', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "saver.save(sess, './model_ch6/dnn_mnist.ckpt', global_step=global_step)    \n",
    "\n",
    "print ('최적화 완료!')\n",
    "\n",
    "###########\n",
    "# 결과 확인 #\n",
    "########## \n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, axis=1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print ('정확도:', sess.run(accuracy,\n",
    "                         feed_dict = {X: mnist.test.images,\n",
    "                                      Y: mnist.test.labels,\n",
    "                                      keep_prob: 1}))\n",
    "\n",
    "########################\n",
    "# 결과 확인 (matplotlib) #\n",
    "#######################\n",
    "\n",
    "labels = sess.run(model, feed_dict={X: mnist.test.images,\n",
    "                                    Y: mnist.test.labels,\n",
    "                                    keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    # 2행 5열의 그래프를 만들고, i + 1 번째에 숫자 이미지를 출력한다.\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    # 이미지를 깨끗하게 출력하기 위해 x와 y의 눈금을 출력하지 않는다.\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    # 출력한 이미지 위에 예측한 숫자를 출력한다.\n",
    "    # np.argmax는 tf.argmax와 같은 기능의 함수이다.\n",
    "    # 결괏값인 labels의 i번째 요소가 원-핫 인코딩 형식으로 되어 있으므로, 해당 배열에서 가장 높은 값을 가진 인덱스를 예측한 숫자로 출력한다.\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    # 1차원 배열로 되어 있는 i번째 이미지를 28 x 28 형식의 배열로 변형하여 이미지 형태로 출력한다.\n",
    "    # cmap 파라미터를 통해 이미지를 그레이스케일로 출력한다.\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)), cmap=plt.cm.gray_r)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
